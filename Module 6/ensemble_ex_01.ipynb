{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0991a0",
   "metadata": {},
   "source": [
    "# üìù Exercise M6.01\n",
    "\n",
    "The aim of this notebook is to investigate if we can tune the hyperparameters\n",
    "of a bagging regressor and evaluate the gain obtained.\n",
    "\n",
    "We will load the California housing dataset and split it into a training and a\n",
    "testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acefaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0, test_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736e486",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac525d2",
   "metadata": {},
   "source": [
    "Create a `BaggingRegressor` and provide a `DecisionTreeRegressor` to its\n",
    "parameter `estimator`. Train the regressor and evaluate its generalization\n",
    "performance on the testing set using the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbc19b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.503279355014996"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "bagged_trees = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=3),\n",
    "    n_estimators=100,\n",
    ")\n",
    "\n",
    "bagged_trees.fit(data_train, target_train)\n",
    "\n",
    "predicted = bagged_trees.predict(data_test)\n",
    "\n",
    "test_score = mean_absolute_error(target_test, predicted)\n",
    "\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff30208",
   "metadata": {},
   "source": [
    "Now, create a `RandomizedSearchCV` instance using the previous model and tune\n",
    "the important parameters of the bagging regressor. Find the best parameters\n",
    "and check if you are able to find a set of parameters that improve the default\n",
    "regressor still using the mean absolute error as a metric.\n",
    "\n",
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">You can list the bagging regressor's parameters using the <tt class=\"docutils literal\">get_params</tt> method.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67b01a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awben\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\awben\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\awben\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\awben\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\awben\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_samples' parameter of BaggingRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 0.0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\awben\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-42.5714017  -50.80792901 -52.16728908 -43.63433291 -48.64734048\n",
      " -63.85037546 -42.51362563 -75.53781754 -39.77870107          nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39.17629203118985"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "# bagged_trees.get_params()\n",
    "\n",
    "distributions = {\n",
    "    \"n_estimators\": [*range(1, 100, 10)],\n",
    "    'max_samples': np.arange(0, 1, 0.1), #if float is the percentage of the size of X\n",
    "    'max_features': [0.2, 0.8, 1.0],\n",
    "    \"estimator__max_depth\": [*range(2, 10, 1)]\n",
    "}\n",
    "\n",
    "randomized_bagging = RandomizedSearchCV(bagged_trees, distributions, scoring=\"neg_mean_absolute_error\", random_state=0)\n",
    "\n",
    "randomized_bagging.fit(data_train, target_train)\n",
    "\n",
    "test_score = - randomized_bagging.score(data_test, target_test) # - to make it positive\n",
    "\n",
    "test_score\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "nbreset": "https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/main/notebooks/ensemble_ex_01.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
